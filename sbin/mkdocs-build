#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.8"
# dependencies = [
#     "mkdocs>=1.5.0",
#     "mkdocs-material>=9.4.0",
#     "playwright>=1.40.0",
# ]
# ///
"""
MkDocs Build v2.0 - Multi-Target Build System

Unified build system for MkDocs documentation with support for multiple output targets:
- mkdocs: Ephemeral build directory for development
- site: Static website output
- electron: Electron desktop application

Features:
- Single unified configuration file
- Multi-target builds in one command
- Built-in version management
- Dynamic mkdocs.yml generation
- Extensible target system

Usage:
  mkdocs-build-v2 --config docs/mkdocs-build.json [--target TARGET]

Examples:
  # Build default target (mkdocs)
  mkdocs-build-v2 --config docs/mkdocs-build.json
  
  # Build specific target
  mkdocs-build-v2 --config docs/mkdocs-build.json --target site
  
  # Build multiple targets
  mkdocs-build-v2 --config docs/mkdocs-build.json --target mkdocs,site
  
  # Build all enabled targets
  mkdocs-build-v2 --config docs/mkdocs-build.json --target all
  
  # Build electron with auto-build
  mkdocs-build-v2 --config docs/mkdocs-build.json --target electron --electron-build

Config File Format (docs/mkdocs-build.json):
  {
    "version": {
      "current": "1.0.0",
      "auto_increment": "patch"
    },
    "project": {
      "name": "My Docs",
      "description": "Documentation",
      "author": "Author Name"
    },
    "source": {
      "docs_dir": ".",
      "content_dirs": ["ARCHITECTURE", "BUSINESS"]
    },
    "targets": {
      "mkdocs": {"enabled": true, "output_dir": "../mkdocs"},
      "site": {"enabled": true, "output_dir": "../site"},
      "electron": {"enabled": false, "output_dir": "../desktop-app"}
    }
  }
"""

from __future__ import annotations

import argparse
import json
import os
import re
import shutil
import subprocess
import sys
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Set

# Version
VERSION = "2.0.0"


class BuildTarget(Enum):
    """Available build targets."""
    MKDOCS = "mkdocs"
    SITE = "site"
    SITE_ZIP = "site-zip"
    COMBINED_HTML = "combined-html"
    PDF = "pdf"
    ELECTRON = "electron"
    GO = "go"
    ALL = "all"


@dataclass
class VersionConfig:
    """Version configuration."""
    current: str = "0.0.1"
    build_count: int = 0
    auto_increment: str = "patch"  # major, minor, patch, none
    
    def increment(self) -> str:
        """Increment version based on auto_increment setting."""
        if self.auto_increment == "none":
            return self.current
        
        match = re.match(r'(\d+)\.(\d+)\.(\d+)', self.current)
        if not match:
            # Fallback for non-standard version
            return f"{self.current}-{datetime.now().strftime('%Y%m%d%H%M%S')}"
        
        major, minor, patch = map(int, match.groups())
        
        if self.auto_increment == "major":
            return f"{major + 1}.0.0"
        elif self.auto_increment == "minor":
            return f"{major}.{minor + 1}.0"
        else:  # patch
            return f"{major}.{minor}.{patch + 1}"


@dataclass
class ProjectConfig:
    """Project metadata configuration."""
    name: str = "Documentation"
    description: str = "Project Documentation"
    author: str = "Author"
    url: Optional[str] = None


@dataclass
class SourceConfig:
    """Source documentation configuration."""
    docs_dir: str = "."
    content_dirs: List[str] = field(default_factory=list)
    assets_dir: str = ".mkdocs-assets"
    asset_subdirs: List[str] = field(default_factory=lambda: ["assets", "javascripts", "stylesheets"])


@dataclass
class MkDocsConfig:
    """MkDocs-specific configuration."""
    theme: str = "material"
    features: List[str] = field(default_factory=lambda: [
        "navigation.tabs",
        "navigation.sections",
        "search.highlight"
    ])
    plugins: List[str] = field(default_factory=lambda: ["search", "offline"])
    extensions: List[str] = field(default_factory=lambda: [
        "admonition",
        "pymdownx.superfences",
        "pymdownx.highlight"
    ])


@dataclass
class TargetConfig:
    """Base target configuration."""
    enabled: bool = True
    output_dir: str = ""


@dataclass
class MkDocsTargetConfig(TargetConfig):
    """MkDocs target configuration."""
    docs_subdir: str = "docs"
    auto_build: bool = True


@dataclass
class SiteTargetConfig(TargetConfig):
    """Static site target configuration."""
    clean_build: bool = True
    minify: bool = False


@dataclass
class ElectronTargetConfig(TargetConfig):
    """Electron target configuration."""
    platforms: List[str] = field(default_factory=lambda: ["mac", "win", "linux"])
    auto_build: bool = False
    code_signing: Dict[str, Any] = field(default_factory=lambda: {"enabled": False, "identity": None})


@dataclass
class GoTargetConfig(TargetConfig):
    """Go binary target configuration."""
    platforms: List[str] = field(default_factory=lambda: ["darwin/amd64", "darwin/arm64", "linux/amd64", "linux/arm64", "windows/amd64", "windows/arm64"])
    auto_build: bool = True


@dataclass
class SiteZipTargetConfig(TargetConfig):
    """Site zip archive target configuration."""
    pass


@dataclass
class CombinedHtmlTargetConfig(TargetConfig):
    """Combined HTML target configuration."""
    with_toc: bool = True
    with_cover: bool = True
    toc_levels: int = 2


@dataclass
class PdfTargetConfig(TargetConfig):
    """PDF target configuration."""
    with_toc: bool = True
    with_cover: bool = True
    toc_levels: int = 2


@dataclass
class UnifiedConfig:
    """Unified build configuration."""
    config_path: Path
    version: VersionConfig
    project: ProjectConfig
    source: SourceConfig
    mkdocs: MkDocsConfig
    targets: Dict[str, TargetConfig]
    
    @property
    def config_dir(self) -> Path:
        """Directory containing the config file."""
        return self.config_path.parent
    
    @property
    def source_dir(self) -> Path:
        """Absolute path to source directory."""
        return self.config_dir / self.source.docs_dir
    
    def log(self, msg: str, emoji: str = "‚ÑπÔ∏è") -> None:
        """Print a log message."""
        print(f"{emoji}  {msg}")


def load_unified_config(config_path: Path) -> UnifiedConfig:
    """Load and parse unified configuration file."""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        print(f"‚ùå Error loading config file {config_path}: {e}", file=sys.stderr)
        sys.exit(1)
    
    # Parse version config
    version_data = data.get('version', {})
    version = VersionConfig(
        current=version_data.get('current', '0.0.1'),
        build_count=version_data.get('build_count', 0),
        auto_increment=version_data.get('auto_increment', 'patch')
    )
    
    # Parse project config
    project_data = data.get('project', {})
    project = ProjectConfig(
        name=project_data.get('name', 'Documentation'),
        description=project_data.get('description', 'Project Documentation'),
        author=project_data.get('author', 'Author'),
        url=project_data.get('url')
    )
    
    # Parse source config
    source_data = data.get('source', {})
    source = SourceConfig(
        docs_dir=source_data.get('docs_dir', '.'),
        content_dirs=source_data.get('content_dirs', []),
        assets_dir=source_data.get('assets_dir', '.mkdocs-assets'),
        asset_subdirs=source_data.get('asset_subdirs', ["assets", "javascripts", "stylesheets"])
    )
    
    # Parse mkdocs config
    mkdocs_data = data.get('mkdocs', {})
    mkdocs = MkDocsConfig(
        theme=mkdocs_data.get('theme', 'material'),
        features=mkdocs_data.get('features', [
            "navigation.tabs",
            "navigation.sections",
            "search.highlight"
        ]),
        plugins=mkdocs_data.get('plugins', ["search", "offline"]),
        extensions=mkdocs_data.get('extensions', [
            "admonition",
            "pymdownx.superfences",
            "pymdownx.highlight"
        ])
    )
    
    # Parse targets
    targets_data = data.get('targets', {})
    targets = {}
    
    if 'mkdocs' in targets_data:
        mkdocs_target = targets_data['mkdocs']
        targets['mkdocs'] = MkDocsTargetConfig(
            enabled=mkdocs_target.get('enabled', True),
            output_dir=mkdocs_target.get('output_dir', '../mkdocs'),
            docs_subdir=mkdocs_target.get('docs_subdir', 'docs'),
            auto_build=mkdocs_target.get('auto_build', True)
        )
    
    if 'site' in targets_data:
        site_target = targets_data['site']
        targets['site'] = SiteTargetConfig(
            enabled=site_target.get('enabled', True),
            output_dir=site_target.get('output_dir', '../site'),
            clean_build=site_target.get('clean_build', True),
            minify=site_target.get('minify', False)
        )
    
    if 'electron' in targets_data:
        electron_target = targets_data['electron']
        targets['electron'] = ElectronTargetConfig(
            enabled=electron_target.get('enabled', False),
            output_dir=electron_target.get('output_dir', '../desktop-app'),
            platforms=electron_target.get('platforms', ["mac", "win", "linux"]),
            auto_build=electron_target.get('auto_build', False),
            code_signing=electron_target.get('code_signing', {"enabled": False, "identity": None})
        )
    
    if 'go' in targets_data:
        go_target = targets_data['go']
        targets['go'] = GoTargetConfig(
            enabled=go_target.get('enabled', True),
            output_dir=go_target.get('output_dir', '../go-dists'),
            platforms=go_target.get('platforms', ["darwin/amd64", "darwin/arm64", "linux/amd64", "linux/arm64", "windows/amd64", "windows/arm64"]),
            auto_build=go_target.get('auto_build', True)
        )
    
    if 'site-zip' in targets_data:
        site_zip_target = targets_data['site-zip']
        targets['site-zip'] = SiteZipTargetConfig(
            enabled=site_zip_target.get('enabled', True),
            output_dir=site_zip_target.get('output_dir', '../site-archives')
        )
    
    if 'combined-html' in targets_data:
        combined_html_target = targets_data['combined-html']
        targets['combined-html'] = CombinedHtmlTargetConfig(
            enabled=combined_html_target.get('enabled', True),
            output_dir=combined_html_target.get('output_dir', '../combined-html'),
            with_toc=combined_html_target.get('with_toc', True),
            with_cover=combined_html_target.get('with_cover', True),
            toc_levels=combined_html_target.get('toc_levels', 2)
        )
    
    if 'pdf' in targets_data:
        pdf_target = targets_data['pdf']
        targets['pdf'] = PdfTargetConfig(
            enabled=pdf_target.get('enabled', True),
            output_dir=pdf_target.get('output_dir', '../pdf-archives'),
            with_toc=pdf_target.get('with_toc', True),
            with_cover=pdf_target.get('with_cover', True),
            toc_levels=pdf_target.get('toc_levels', 2)
        )
    
    return UnifiedConfig(
        config_path=config_path,
        version=version,
        project=project,
        source=source,
        mkdocs=mkdocs,
        targets=targets
    )


def save_version(config: UnifiedConfig) -> None:
    """Save updated version back to config file."""
    try:
        with open(config.config_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        data['version']['current'] = config.version.current
        data['version']['build_count'] = config.version.build_count
        
        with open(config.config_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2)
            f.write('\n')  # Add trailing newline
    except Exception as e:
        print(f"‚ö†Ô∏è  Warning: Could not save version: {e}", file=sys.stderr)


def generate_mkdocs_yml(config: UnifiedConfig, output_path: Path) -> None:
    """Generate mkdocs.yml from unified config."""
    # Auto-detect content dirs if not specified
    content_dirs = config.source.content_dirs
    if not content_dirs:
        content_dirs = []
        for item in config.source_dir.iterdir():
            if item.is_dir() and not item.name.startswith('.') and any(item.rglob('*.md')):
                content_dirs.append(item.name)
        content_dirs = sorted(content_dirs)
    
    # Build navigation structure with all files
    def build_nav_for_dir(base_path: Path, dir_name: str, indent: int = 2) -> List[str]:
        """Recursively build navigation entries for a directory."""
        nav_lines = []
        dir_path = base_path / dir_name
        
        if not dir_path.exists() or not dir_path.is_dir():
            return nav_lines
        
        # Collect all markdown files and subdirectories
        md_files = []
        subdirs = []
        
        for item in sorted(dir_path.iterdir()):
            if item.is_file() and item.suffix == '.md':
                md_files.append(item.name)
            elif item.is_dir() and not item.name.startswith('.'):
                # Check if subdir has markdown files
                if any(item.rglob('*.md')):
                    subdirs.append(item.name)
        
        # Start with section header
        spaces = " " * indent
        
        # If README.md exists, use it as the section index
        if 'README.md' in md_files:
            nav_lines.append(f"{spaces}- {dir_name}:")
            nav_lines.append(f"{spaces}  - Overview: {dir_name}/README.md")
            md_files.remove('README.md')
        else:
            nav_lines.append(f"{spaces}- {dir_name}:")
        
        # Add other markdown files in this directory
        for md_file in md_files:
            # Create a nice title from filename
            title = md_file.replace('.md', '').replace('_', ' ').replace('-', ' ')
            nav_lines.append(f"{spaces}  - {title}: {dir_name}/{md_file}")
        
        # Add subdirectories recursively
        for subdir in subdirs:
            subdir_path = dir_path / subdir
            sub_md_files = list(subdir_path.glob('*.md'))
            
            if sub_md_files:
                # Check if subdir has README.md
                readme_path = subdir_path / 'README.md'
                if readme_path.exists():
                    nav_lines.append(f"{spaces}  - {subdir}:")
                    nav_lines.append(f"{spaces}    - Overview: {dir_name}/{subdir}/README.md")
                    # Add other files in subdir
                    for md_file in sorted(subdir_path.glob('*.md')):
                        if md_file.name != 'README.md':
                            title = md_file.stem.replace('_', ' ').replace('-', ' ')
                            nav_lines.append(f"{spaces}    - {title}: {dir_name}/{subdir}/{md_file.name}")
                else:
                    # No README, just list files under subdir name
                    nav_lines.append(f"{spaces}  - {subdir}:")
                    for md_file in sorted(subdir_path.glob('*.md')):
                        title = md_file.stem.replace('_', ' ').replace('-', ' ')
                        nav_lines.append(f"{spaces}    - {title}: {dir_name}/{subdir}/{md_file.name}")
        
        return nav_lines
    
    # Build complete navigation
    nav_items = []
    
    # Check if index.md exists at root and add it first
    index_path = config.source_dir / "index.md"
    if index_path.exists():
        nav_items.append("  - Home: index.md")
    
    # Add all content directories
    for dir_name in content_dirs:
        nav_items.extend(build_nav_for_dir(config.source_dir, dir_name))
    
    nav_section = "\n".join(nav_items) if nav_items else "  - Home: index.md"
    
    # Generate YAML content
    yml_content = f"""site_name: {config.project.name}
site_description: {config.project.description}
site_author: {config.project.author}

# Theme
theme:
  name: material
  features:
"""
    for feature in config.mkdocs.features:
        yml_content += f"    - {feature}\n"
    
    yml_content += """  palette:
    - scheme: default
      primary: blue
      accent: blue
      toggle:
        icon: material/brightness-7
        name: Switch to dark mode
    - scheme: slate
      primary: blue
      accent: blue
      toggle:
        icon: material/brightness-4
        name: Switch to light mode

# Navigation
nav:
"""
    yml_content += nav_section + "\n"
    
    yml_content += "\n# Plugins\nplugins:\n"
    for plugin in config.mkdocs.plugins:
        yml_content += f"  - {plugin}\n"
    
    yml_content += "\n# Extensions\nmarkdown_extensions:\n"
    for ext in config.mkdocs.extensions:
        if ext == "pymdownx.superfences":
            yml_content += """  - pymdownx.superfences:
      custom_fences:
        - name: mermaid
          class: mermaid
          format: !!python/name:pymdownx.superfences.fence_code_format
"""
        elif ext == "pymdownx.highlight":
            yml_content += """  - pymdownx.highlight:
      anchor_linenums: true
"""
        elif ext == "pymdownx.tabbed":
            yml_content += """  - pymdownx.tabbed:
      alternate_style: true
"""
        elif ext == "pymdownx.tasklist":
            yml_content += """  - pymdownx.tasklist:
      custom_checkbox: true
"""
        elif ext == "pymdownx.emoji":
            yml_content += """  - pymdownx.emoji:
      emoji_index: !!python/name:material.extensions.emoji.twemoji
      emoji_generator: !!python/name:material.extensions.emoji.to_svg
"""
        else:
            yml_content += f"  - {ext}\n"
    
    # Write to file
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(yml_content)
    
    config.log(f"Generated mkdocs.yml", "")


def auto_detect_content_dirs(source_dir: Path) -> List[str]:
    """Auto-detect content directories in the source directory."""
    content_dirs = []
    if not source_dir.exists():
        return content_dirs
    
    for item in source_dir.iterdir():
        if item.is_dir() and not item.name.startswith('.'):
            if any(item.rglob('*.md')):
                content_dirs.append(item.name)
    
    return sorted(content_dirs)


def build_mkdocs_target(config: UnifiedConfig, target_config: MkDocsTargetConfig) -> bool:
    """Build MkDocs ephemeral directory target."""
    config.log(f"\n=== Building MkDocs Target ===", "üìÅ")
    
    # Resolve output directory
    output_dir = config.config_dir / target_config.output_dir
    docs_dir = output_dir / target_config.docs_subdir
    
    # Clean existing build
    if output_dir.exists():
        config.log(f"Removing existing {output_dir.name}/", "üóëÔ∏è")
        shutil.rmtree(output_dir)
    
    # Create structure
    docs_dir.mkdir(parents=True, exist_ok=True)
    config.log(f"Created {output_dir.relative_to(config.config_dir.parent)}/", "üìÅ")
    
    # Copy index.md if it exists
    index_src = config.source_dir / "index.md"
    if index_src.exists():
        shutil.copy2(index_src, docs_dir / "index.md")
        config.log(f"Synced index.md", "")
    
    # Auto-detect content dirs if not specified
    content_dirs = config.source.content_dirs
    if not content_dirs:
        content_dirs = auto_detect_content_dirs(config.source_dir)
        if content_dirs:
            config.log(f"Auto-detected: {', '.join(content_dirs)}", "üîç")
    
    # Sync content directories
    for dir_name in content_dirs:
        src_dir = config.source_dir / dir_name
        dst_dir = docs_dir / dir_name
        
        if src_dir.exists() and src_dir.is_dir():
            shutil.copytree(src_dir, dst_dir)
            config.log(f"Synced {dir_name}/", "üìÅ")
    
    # Sync assets
    assets_source = config.source_dir / config.source.assets_dir
    if assets_source.exists():
        for asset_subdir in config.source.asset_subdirs:
            src_asset = assets_source / asset_subdir
            dst_asset = docs_dir / asset_subdir
            
            if src_asset.exists() and src_asset.is_dir():
                shutil.copytree(src_asset, dst_asset)
                config.log(f"Synced {asset_subdir}/ assets", "üé®")
    
    # Generate mkdocs.yml in output directory
    mkdocs_yml_path = output_dir / "mkdocs.yml"
    generate_mkdocs_yml(config, mkdocs_yml_path)
    
    # Run mkdocs build if enabled
    if target_config.auto_build:
        config.log("Building MkDocs site...", "")
        try:
            cmd = ["mkdocs", "build", "--clean", "--config-file", str(mkdocs_yml_path)]
            subprocess.run(cmd, check=True, cwd=output_dir.parent)
            config.log("MkDocs build successful!", "‚úÖ")
        except subprocess.CalledProcessError as e:
            print(f"‚ùå MkDocs build failed: {e}", file=sys.stderr)
            return False
        except FileNotFoundError:
            print(f"‚ùå mkdocs not found. Install with: uv pip install mkdocs mkdocs-material", file=sys.stderr)
            return False
    
    return True


def build_site_target(config: UnifiedConfig, target_config: SiteTargetConfig) -> bool:
    """Build static site target."""
    config.log(f"\n=== Building Site Target ===", "üåê")
    
    # Resolve output directory
    output_dir = config.config_dir / target_config.output_dir
    
    # Clean if requested
    if target_config.clean_build and output_dir.exists():
        config.log(f"Cleaning {output_dir.name}/", "üóëÔ∏è")
        shutil.rmtree(output_dir)
    
    # Create temporary mkdocs directory for building
    temp_build_dir = config.config_dir / ".temp-mkdocs-build"
    temp_docs_dir = temp_build_dir / "docs"
    
    try:
        # Create temp structure
        temp_docs_dir.mkdir(parents=True, exist_ok=True)
        
        # Copy index.md if it exists
        index_src = config.source_dir / "index.md"
        if index_src.exists():
            shutil.copy2(index_src, temp_docs_dir / "index.md")
        
        # Sync content
        content_dirs = config.source.content_dirs or auto_detect_content_dirs(config.source_dir)
        for dir_name in content_dirs:
            src_dir = config.source_dir / dir_name
            dst_dir = temp_docs_dir / dir_name
            if src_dir.exists():
                shutil.copytree(src_dir, dst_dir)
        
        # Sync assets
        assets_source = config.source_dir / config.source.assets_dir
        if assets_source.exists():
            for asset_subdir in config.source.asset_subdirs:
                src_asset = assets_source / asset_subdir
                dst_asset = temp_docs_dir / asset_subdir
                if src_asset.exists():
                    shutil.copytree(src_asset, dst_asset)
        
        # Generate mkdocs.yml
        mkdocs_yml = temp_build_dir / "mkdocs.yml"
        generate_mkdocs_yml(config, mkdocs_yml)
        
        # Build site
        config.log("Building static site...", "")
        cmd = ["mkdocs", "build", "--clean", "--site-dir", str(output_dir.resolve()), "--config-file", str(mkdocs_yml.resolve())]
        subprocess.run(cmd, check=True, cwd=str(temp_build_dir.resolve()))
        
        config.log(f"Site built: {output_dir.relative_to(config.config_dir.parent)}/", "‚úÖ")
        
    except Exception as e:
        print(f"‚ùå Site build failed: {e}", file=sys.stderr)
        return False
    finally:
        # Clean up temp directory
        if temp_build_dir.exists():
            shutil.rmtree(temp_build_dir)
    
    return True


def build_electron_target(config: UnifiedConfig, target_config: ElectronTargetConfig, auto_build: bool = False, platforms: Optional[List[str]] = None) -> bool:
    """Build Electron desktop app target."""
    config.log(f"\n=== Building Electron Target ===", "‚ö°")
    
    # Resolve output directory
    output_dir = config.config_dir / target_config.output_dir
    site_dir = output_dir / "site"
    
    # Create output structure
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Build static site using temporary mkdocs build
    temp_build_dir = config.config_dir / ".temp-electron-build"
    temp_docs_dir = temp_build_dir / "docs"
    
    try:
        # Create temp structure
        temp_docs_dir.mkdir(parents=True, exist_ok=True)
        
        # Copy index.md if it exists
        index_src = config.source_dir / "index.md"
        if index_src.exists():
            shutil.copy2(index_src, temp_docs_dir / "index.md")
        
        # Sync content
        content_dirs = config.source.content_dirs or auto_detect_content_dirs(config.source_dir)
        for dir_name in content_dirs:
            src_dir = config.source_dir / dir_name
            dst_dir = temp_docs_dir / dir_name
            if src_dir.exists():
                shutil.copytree(src_dir, dst_dir)
                config.log(f"Synced {dir_name}/", "üìÅ")
        
        # Sync assets
        assets_source = config.source_dir / config.source.assets_dir
        if assets_source.exists():
            for asset_subdir in config.source.asset_subdirs:
                src_asset = assets_source / asset_subdir
                dst_asset = temp_docs_dir / asset_subdir
                if src_asset.exists():
                    shutil.copytree(src_asset, dst_asset)
        
        # Generate mkdocs.yml
        mkdocs_yml = temp_build_dir / "mkdocs.yml"
        generate_mkdocs_yml(config, mkdocs_yml)
        
        # Build static site
        config.log("Building static site for Electron...", "")
        if site_dir.exists():
            shutil.rmtree(site_dir)
        
        cmd = ["mkdocs", "build", "--clean", "--site-dir", str(site_dir.resolve()), "--config-file", str(mkdocs_yml.resolve())]
        subprocess.run(cmd, check=True, cwd=str(temp_build_dir.resolve()))
        
        config.log(f"Static site built", "‚úÖ")
        
    except Exception as e:
        print(f"‚ùå Static site build failed: {e}", file=sys.stderr)
        return False
    finally:
        # Clean up temp directory
        if temp_build_dir.exists():
            shutil.rmtree(temp_build_dir)
    
    # Generate Electron files
    electron_dir = output_dir / "electron"
    electron_dir.mkdir(exist_ok=True)
    
    # main.js - Load static site directly
    main_js_content = f"""const {{ app, BrowserWindow, protocol }} = require('electron');
const path = require('path');
const url = require('url');

let mainWindow;

function createWindow() {{
  mainWindow = new BrowserWindow({{
    width: 1400,
    height: 900,
    webPreferences: {{
      nodeIntegration: false,
      contextIsolation: true,
      webSecurity: true
    }},
    title: '{config.project.name} v{config.version.current}'
  }});
  
  // Determine the base directory (handle both dev and packaged app)
  const isDev = !app.isPackaged;
  const siteDir = isDev 
    ? path.join(__dirname, '..', 'site')
    : path.join(process.resourcesPath, 'app.asar.unpacked', 'site');
  
  const indexPath = path.join(siteDir, 'index.html');
  
  console.log('Loading site from:', siteDir);
  console.log('Index file:', indexPath);
  
  // Load the index.html file
  mainWindow.loadFile(indexPath);
  
  mainWindow.on('closed', () => {{
    mainWindow = null;
  }});
}}

app.on('ready', () => {{
  createWindow();
}});

app.on('window-all-closed', () => {{
  app.quit();
}});

app.on('activate', () => {{
  if (mainWindow === null) {{
    createWindow();
  }}
}});
"""
    (electron_dir / "main.js").write_text(main_js_content)
    
    # package.json
    package_json = {
        "name": config.project.name.lower().replace(' ', '-'),
        "version": config.version.current,
        "description": config.project.description,
        "author": config.project.author,
        "main": "electron/main.js",
        "scripts": {
            "start": "electron .",
            "build": "electron-builder",
            "build:mac": "electron-builder --mac",
            "build:win": "electron-builder --win",
            "build:linux": "electron-builder --linux",
            "build:all": "electron-builder -mwl"
        },
        "devDependencies": {
            "electron": "^28.0.0",
            "electron-builder": "^24.9.0"
        },
        "build": {
            "appId": f"com.{config.project.author.lower().replace(' ', '')}.{config.project.name.lower().replace(' ', '')}",
            "productName": config.project.name.replace(' ', '_'),
            "artifactName": "${productName}-${version}-${arch}.${ext}",
            "directories": {
                "output": "dists"
            },
            "files": [
                "electron/**/*",
                "site/**/*"
            ],
            "asarUnpack": [
                "site/**/*"
            ],
            "mac": {
                "category": "public.app-category.developer-tools",
                "target": ["dmg", "zip"]
            },
            "win": {
                "target": ["nsis"]
            },
            "linux": {
                "target": ["AppImage"],
                "category": "Development"
            }
        }
    }
    
    with open(output_dir / "package.json", 'w') as f:
        json.dump(package_json, f, indent=2)
        f.write('\n')
    
    config.log("Generated Electron files", "‚ö°")
    
    # Build Electron apps if requested
    if auto_build or target_config.auto_build:
        build_platforms = platforms or target_config.platforms
        config.log(f"Building Electron apps for: {', '.join(build_platforms)}", "üî®")
        
        # Install dependencies
        config.log("Installing Node.js dependencies...", "üì¶")
        try:
            subprocess.run(["npm", "install"], cwd=output_dir, check=True, capture_output=True)
        except subprocess.CalledProcessError as e:
            print(f"‚ùå npm install failed: {e}", file=sys.stderr)
            return False
        
        # Build for platforms
        if "all" in build_platforms:
            cmd = ["npm", "run", "build:all"]
        else:
            for platform in build_platforms:
                cmd = ["npm", "run", f"build:{platform}"]
                try:
                    subprocess.run(cmd, cwd=output_dir, check=True)
                    config.log(f"Built for {platform}", "‚úÖ")
                except subprocess.CalledProcessError as e:
                    print(f"‚ùå Build failed for {platform}: {e}", file=sys.stderr)
                    return False
    
    config.log(f"Electron app ready: {output_dir.relative_to(config.config_dir.parent)}/", "‚úÖ")
    return True


def build_go_target(config: UnifiedConfig, target_config: GoTargetConfig, platforms: Optional[List[str]] = None) -> bool:
    """Build Go static binary target."""
    config.log(f"\n=== Building Go Binary Target ===", "üîß")
    
    # Resolve output directory
    output_dir = config.config_dir / target_config.output_dir
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Create temporary build directory
    temp_build_dir = config.config_dir / ".temp-go-build"
    temp_site_dir = temp_build_dir / "site"
    
    try:
        # Build static site first
        temp_docs_dir = temp_build_dir / "docs"
        temp_docs_dir.mkdir(parents=True, exist_ok=True)
        
        # Copy index.md if it exists
        index_src = config.source_dir / "index.md"
        if index_src.exists():
            shutil.copy2(index_src, temp_docs_dir / "index.md")
        
        # Sync content
        content_dirs = config.source.content_dirs or auto_detect_content_dirs(config.source_dir)
        for dir_name in content_dirs:
            src_dir = config.source_dir / dir_name
            dst_dir = temp_docs_dir / dir_name
            if src_dir.exists():
                shutil.copytree(src_dir, dst_dir)
        
        # Sync assets
        assets_source = config.source_dir / config.source.assets_dir
        if assets_source.exists():
            for asset_subdir in config.source.asset_subdirs:
                src_asset = assets_source / asset_subdir
                dst_asset = temp_docs_dir / asset_subdir
                if src_asset.exists():
                    shutil.copytree(src_asset, dst_asset)
        
        # Generate mkdocs.yml (without offline plugin for Mermaid support)
        mkdocs_yml = temp_build_dir / "mkdocs.yml"
        # Temporarily remove offline plugin for Go builds to support Mermaid
        original_plugins = config.mkdocs.plugins
        config.mkdocs.plugins = [p for p in original_plugins if p != "offline"]
        generate_mkdocs_yml(config, mkdocs_yml)
        config.mkdocs.plugins = original_plugins
        
        # Build static site
        config.log("Building static site for Go binary...", "")
        if temp_site_dir.exists():
            shutil.rmtree(temp_site_dir)
        
        cmd = ["mkdocs", "build", "--clean", "--site-dir", str(temp_site_dir.resolve()), "--config-file", str(mkdocs_yml.resolve())]
        subprocess.run(cmd, check=True, cwd=str(temp_build_dir.resolve()))
        
        config.log(f"Static site built", "‚úÖ")
        
        # Copy Go template
        template_path = config.config_dir.parent / "scripts" / "templates" / "static_web_server.go"
        if not template_path.exists():
            print(f"‚ùå Go template not found: {template_path}", file=sys.stderr)
            return False
        
        shutil.copy2(template_path, temp_build_dir / "main.go")
        config.log("Copied Go template", "üìù")
        
        # Create go.mod
        go_mod_content = f"""module mytalent-docs

go 1.21
"""
        (temp_build_dir / "go.mod").write_text(go_mod_content)
        
        # Build for each platform
        build_platforms = platforms or target_config.platforms
        config.log(f"Building Go binaries for: {', '.join(build_platforms)}", "üî®")
        
        for platform in build_platforms:
            goos, goarch = platform.split('/')
            
            # Determine output filename - match Electron naming convention
            # Electron: "MyTalent_Docs-1.0.39-arm64.dmg"
            # Go: "MyTalent_Docs-1.0.39-darwin-arm64" (with OS for clarity)
            binary_name = f"{config.project.name.replace(' ', '_')}-{config.version.current}-{goos}-{goarch}"
            if goos == "windows":
                binary_name += ".exe"
            
            output_path = output_dir / binary_name
            
            # Build command
            env = os.environ.copy()
            env['GOOS'] = goos
            env['GOARCH'] = goarch
            env['CGO_ENABLED'] = '0'
            
            config.log(f"Building {goos}/{goarch}...", "")
            
            try:
                result = subprocess.run(
                    ["go", "build", "-ldflags", "-s -w", "-o", str(output_path.resolve()), "main.go"],
                    cwd=temp_build_dir,
                    env=env,
                    check=True,
                    capture_output=True,
                    text=True
                )
                
                # Check if file was created
                if not output_path.exists():
                    print(f"‚ùå Build succeeded but binary not found: {output_path}", file=sys.stderr)
                    return False
                
                # Get file size
                size_mb = output_path.stat().st_size / (1024 * 1024)
                config.log(f"Built {binary_name} ({size_mb:.1f}MB)", "‚úÖ")
                
            except subprocess.CalledProcessError as e:
                print(f"‚ùå Build failed for {platform}: {e}", file=sys.stderr)
                if e.stdout:
                    print("STDOUT:", e.stdout, file=sys.stderr)
                if e.stderr:
                    print("STDERR:", e.stderr, file=sys.stderr)
                return False
        
    except Exception as e:
        print(f"‚ùå Go build failed: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return False
    finally:
        # Clean up temp directory
        if temp_build_dir.exists():
            shutil.rmtree(temp_build_dir)
    
    config.log(f"Go binaries ready: {output_dir.relative_to(config.config_dir.parent)}/", "‚úÖ")
    return True


def build_site_zip_target(config: UnifiedConfig, target_config: SiteZipTargetConfig) -> bool:
    """Build site zip archive target."""
    config.log(f"\n=== Building Site Zip Archive ===", "üì¶")
    
    # First ensure the site is built
    site_dir = config.config_dir / "../site"
    if not site_dir.exists():
        config.log("Site directory not found, building site first...", "")
        # Build site target first
        if 'site' in config.targets:
            site_config = config.targets['site']
            if isinstance(site_config, SiteTargetConfig):
                if not build_site_target(config, site_config):
                    return False
        else:
            print(f"‚ùå Site target not configured", file=sys.stderr)
            return False
    
    # Resolve output directory
    output_dir = config.config_dir / target_config.output_dir
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Create zip filename
    zip_filename = f"{config.project.name.replace(' ', '_')}-{config.version.current}-site.zip"
    zip_path = output_dir / zip_filename
    
    # Remove existing zip if it exists
    if zip_path.exists():
        zip_path.unlink()
    
    config.log(f"Creating zip archive: {zip_filename}", "")
    
    try:
        # Create zip archive
        import zipfile
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            # Walk through site directory and add all files
            for root, dirs, files in os.walk(site_dir):
                for file in files:
                    file_path = Path(root) / file
                    arcname = file_path.relative_to(site_dir)
                    zipf.write(file_path, arcname)
        
        # Get file size
        size_mb = zip_path.stat().st_size / (1024 * 1024)
        config.log(f"Created {zip_filename} ({size_mb:.1f}MB)", "‚úÖ")
        
    except Exception as e:
        print(f"‚ùå Zip creation failed: {e}", file=sys.stderr)
        return False
    
    config.log(f"Site archive ready: {output_dir.relative_to(config.config_dir.parent)}/", "‚úÖ")
    return True


def build_combined_html_target(config: UnifiedConfig, target_config: CombinedHtmlTargetConfig) -> bool:
    """Build combined HTML documentation target."""
    config.log(f"\n=== Building Combined HTML Documentation ===", "üìÑ")
    
    # First ensure the site is built
    site_dir = config.config_dir / "../site"
    if not site_dir.exists():
        config.log("Site directory not found, building site first...", "")
        if 'site' in config.targets:
            site_config = config.targets['site']
            if isinstance(site_config, SiteTargetConfig):
                if not build_site_target(config, site_config):
                    return False
        else:
            print(f"‚ùå Site target not configured", file=sys.stderr)
            return False
    
    # Resolve output directory
    output_dir = config.config_dir / target_config.output_dir
    output_dir.mkdir(parents=True, exist_ok=True)
    
    html_filename = f"{config.project.name.replace(' ', '_')}-{config.version.current}-combined.html"
    html_path = output_dir / html_filename
    
    config.log("Building combined HTML...", "")
    
    try:
        # Build navigation order from content directories
        html_files = []
        
        # Start with index.html if it exists
        index_file = site_dir / "index.html"
        if index_file.exists():
            html_files.append(index_file)
        
        # Then add files in the order of content_dirs
        content_dirs = config.source.content_dirs or auto_detect_content_dirs(config.source_dir)
        for dir_name in content_dirs:
            section_dir = site_dir / dir_name
            if section_dir.exists() and section_dir.is_dir():
                # Add section index first
                section_index = section_dir / "index.html"
                if section_index.exists():
                    html_files.append(section_index)
                
                # Then add all other pages in this section (sorted)
                for html_file in sorted(section_dir.rglob("*.html")):
                    if html_file != section_index and html_file.name not in ['404.html', 'search.html']:
                        html_files.append(html_file)
        
        # Add any remaining HTML files not in content dirs
        for html_file in sorted(site_dir.rglob("*.html")):
            if (html_file not in html_files and 
                html_file.name not in ['404.html', 'search.html'] and
                html_file != index_file):
                html_files.append(html_file)
        
        config.log(f"Found {len(html_files)} pages to include", "")
        
        # Build combined HTML
        combined_html = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>{config.project.name} v{config.version.current}</title>
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }}
        .cover-page {{
            text-align: center;
            padding: 100px 0;
            border-bottom: 2px solid #eee;
            margin-bottom: 50px;
        }}
        .cover-page h1 {{
            font-size: 48px;
            margin-bottom: 20px;
        }}
        .cover-page .version {{
            font-size: 24px;
            color: #666;
            margin-bottom: 10px;
        }}
        .cover-page .description {{
            font-size: 18px;
            color: #888;
            margin-bottom: 50px;
        }}
        .cover-page .author {{
            font-size: 16px;
            color: #666;
        }}
        .toc {{
            border: 2px solid #3498db;
            border-radius: 8px;
            padding: 40px;
            margin-bottom: 50px;
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }}
        .toc h2 {{
            font-size: 36px;
            margin-bottom: 30px;
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 15px;
        }}
        .toc ul {{
            list-style: none;
            padding-left: 0;
        }}
        .toc li {{
            margin: 4px 0;
            padding-left: 0;
            line-height: 1.4;
        }}
        .toc li.level-1 {{
            font-weight: 600;
            font-size: 15px;
            margin-top: 8px;
            padding-left: 0;
        }}
        .toc li.level-1.section-header {{
            font-weight: 700;
            font-size: 16px;
            margin-top: 15px;
            margin-bottom: 5px;
            color: #2c3e50;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }}
        .toc li.level-1.section-header::before {{
            content: "üìÅ ";
            margin-right: 8px;
        }}
        .toc li.level-2 {{
            padding-left: 20px;
            font-size: 13px;
            color: #555;
        }}
        .toc li.level-3 {{
            padding-left: 40px;
            font-size: 12px;
            color: #666;
        }}
        .toc li.level-4 {{
            padding-left: 60px;
            font-size: 11px;
            color: #777;
        }}
        .toc li.level-1::before {{
            content: "üìÑ ";
            margin-right: 8px;
        }}
        .toc li.level-2::before {{
            content: "‚ñ∏ ";
            margin-right: 6px;
            color: #3498db;
        }}
        .toc li.level-3::before {{
            content: "¬∑ ";
            margin-right: 6px;
            color: #95a5a6;
        }}
        .toc li.level-4::before {{
            content: "- ";
            margin-right: 6px;
            color: #bdc3c7;
        }}
        .toc a {{
            color: #2c3e50;
            text-decoration: none;
            transition: color 0.2s;
        }}
        .toc a:hover {{
            color: #3498db;
            text-decoration: underline;
        }}
        .page-content {{
            border-top: 2px solid #eee;
            padding-top: 30px;
            margin-top: 30px;
        }}
        h1 {{
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }}
        h2 {{
            color: #34495e;
            margin-top: 30px;
        }}
        pre {{
            background: #f6f8fa;
            padding: 16px;
            overflow-x: auto;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }}
        code {{
            background: #f6f8fa;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Monaco', 'Menlo', 'Courier New', monospace;
        }}
        table {{
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
        }}
        th, td {{
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }}
        th {{
            background-color: #f6f8fa;
            font-weight: 600;
        }}
        img {{
            max-width: 100%;
            height: auto;
        }}
        .back-to-top {{
            position: fixed;
            bottom: 20px;
            right: 20px;
            background: #3498db;
            color: white;
            padding: 10px 20px;
            border-radius: 5px;
            text-decoration: none;
        }}
        .back-to-top:hover {{
            background: #2980b9;
        }}
    </style>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        // Initialize Mermaid when page loads
        document.addEventListener('DOMContentLoaded', function() {{
            // Unwrap code tags inside mermaid pre blocks
            document.querySelectorAll('pre.mermaid code').forEach(function(code) {{
                var pre = code.parentElement;
                pre.textContent = code.textContent;
            }});
            
            // Initialize Mermaid
            mermaid.initialize({{ 
                startOnLoad: true,
                theme: 'default'
            }});
            mermaid.run();
        }});
    </script>
</head>
<body>
"""
        
        if target_config.with_cover:
            combined_html += f"""    <!-- Cover Page -->
    <div class="cover-page" id="top">
        <h1>{config.project.name}</h1>
        <div class="version">Version {config.version.current}</div>
        <div class="description">{config.project.description}</div>
        <div class="author">¬© {config.project.author}</div>
        <div style="margin-top: 50px; color: #999;">
            Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        </div>
    </div>
"""
        
        if target_config.with_toc:
            combined_html += """    <!-- Table of Contents -->
    <div class="toc">
        <h2>üìö Table of Contents</h2>
        <ul>
"""
            
            # Extract headers from each page for multi-level TOC
            from html.parser import HTMLParser
            
            class HeaderExtractor(HTMLParser):
                def __init__(self, max_level=2):
                    super().__init__()
                    self.headers = []
                    self.max_level = max_level
                    self.current_tag = None
                    self.current_text = []
                    
                def handle_starttag(self, tag, attrs):
                    if tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                        level = int(tag[1])
                        if level <= self.max_level:
                            self.current_tag = tag
                            self.current_text = []
                            # Get id if present
                            self.current_id = dict(attrs).get('id', '')
                    
                def handle_endtag(self, tag):
                    if tag == self.current_tag and self.current_tag:
                        level = int(self.current_tag[1])
                        text = ''.join(self.current_text).strip()
                        if text:
                            self.headers.append((level, text, self.current_id))
                        self.current_tag = None
                        self.current_text = []
                    
                def handle_data(self, data):
                    if self.current_tag:
                        self.current_text.append(data)
            
            # Build TOC with headers grouped by section
            current_section = None
            
            for idx, html_file in enumerate(html_files):
                try:
                    with open(html_file, 'r', encoding='utf-8') as f:
                        html_content = f.read()
                    
                    rel_path = html_file.relative_to(site_dir)
                    
                    # Check if we're in a new section (directory)
                    if rel_path.parent != Path('.'):
                        section_name = rel_path.parent.name.replace('-', ' ').replace('_', ' ').title()
                        if section_name != current_section:
                            # Add section header
                            combined_html += f'            <li class="level-1 section-header">{section_name}</li>\n'
                            current_section = section_name
                        page_level = 2  # Pages under sections are level 2
                    else:
                        page_level = 1  # Root pages are level 1
                    
                    # Extract meaningful title from the page
                    page_title = None
                    # Try to get title from <title> tag or first <h1>
                    import re
                    title_match = re.search(r'<title[^>]*>([^<]+)</title>', html_content)
                    if title_match:
                        page_title = title_match.group(1).strip()
                        # Remove site name suffix if present
                        if ' - ' in page_title:
                            page_title = page_title.split(' - ')[0].strip()
                    
                    # Fallback to filename-based title
                    if not page_title or page_title.lower() == 'index':
                        if rel_path.stem.lower() == 'index':
                            # Use parent directory name for index pages
                            if rel_path.parent != Path('.'):
                                page_title = "Overview"  # Index pages become "Overview"
                            else:
                                page_title = "Home"
                        else:
                            page_title = rel_path.stem.replace('-', ' ').replace('_', ' ').title()
                    
                    # Add page entry
                    combined_html += f'            <li class="level-{page_level}"><a href="#page-{idx}">{page_title}</a></li>\n'
                    
                    # Extract and add headers if toc_levels > 1
                    if target_config.toc_levels > 1:
                        header_parser = HeaderExtractor(max_level=target_config.toc_levels)
                        header_parser.feed(html_content)
                        
                        for level, header_text, header_id in header_parser.headers:
                            if level > 1:  # Skip h1 as it's usually the page title
                                # Use the original header ID if present, otherwise create one
                                if header_id:
                                    anchor = f"page-{idx}-{header_id}"
                                else:
                                    # Create a slug from the header text
                                    slug = header_text.lower().replace(' ', '-').replace('/', '-')
                                    slug = ''.join(c for c in slug if c.isalnum() or c == '-')
                                    anchor = f"page-{idx}-{slug}"
                                # Headers under pages are one level deeper
                                header_level = page_level + 1
                                combined_html += f'            <li class="level-{header_level}"><a href="#{anchor}">{header_text}</a></li>\n'
                
                except Exception as e:
                    # Fallback to simple entry
                    combined_html += f'            <li class="level-{page_level}"><a href="#page-{idx}">{page_title}</a></li>\n'
            
            combined_html += """        </ul>
    </div>
"""
        
        combined_html += """    <!-- Page Content -->
"""
        
        # Extract and combine content from each HTML file
        from html.parser import HTMLParser
        
        class ContentExtractor(HTMLParser):
            def __init__(self, page_idx, html_files_map):
                super().__init__()
                self.in_article = False
                self.skip_depth = 0
                self.content = []
                self.page_idx = page_idx
                self.html_files_map = html_files_map  # Map of relative paths to page indices
                
            def handle_starttag(self, tag, attrs):
                attrs_dict = dict(attrs)
                class_name = attrs_dict.get('class', '')
                
                # Start capturing when we find the article content
                if tag == 'article' and 'md-content__inner' in class_name:
                    self.in_article = True
                    return
                
                # Skip navigation elements even inside article
                if self.in_article:
                    # Skip navigation, sidebars, headers, footers, table of contents
                    if (tag in ['nav', 'aside', 'header', 'footer'] or
                        'md-nav' in class_name or
                        'md-sidebar' in class_name or
                        'md-header' in class_name or
                        'md-footer' in class_name or
                        'md-source' in class_name or
                        'md-search' in class_name or
                        'md-content__button' in class_name):
                        self.skip_depth += 1
                        return
                    
                    if self.skip_depth == 0:
                        new_attrs = []
                        
                        # Add page-specific prefix to header IDs for unique anchors
                        if tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                            for k, v in attrs:
                                if k == 'id':
                                    new_attrs.append((k, f'page-{self.page_idx}-{v}'))
                                else:
                                    new_attrs.append((k, v))
                            attrs = new_attrs
                        # Rewrite internal links to point to pages in combined HTML
                        elif tag == 'a':
                            for k, v in attrs:
                                if k == 'href':
                                    # Check if it's an internal link
                                    if v and not v.startswith(('http://', 'https://', 'mailto:', '#', '//')):
                                        # Parse the link
                                        if '#' in v:
                                            link_path, anchor = v.split('#', 1)
                                        else:
                                            link_path, anchor = v, ''
                                        
                                        # Normalize the path
                                        from urllib.parse import unquote
                                        link_path = unquote(link_path)
                                        
                                        # Try to find the target page
                                        target_idx = None
                                        for rel_path_str, idx in self.html_files_map.items():
                                            if link_path in rel_path_str or rel_path_str.endswith(link_path):
                                                target_idx = idx
                                                break
                                        
                                        # Rewrite the link
                                        if target_idx is not None:
                                            if anchor:
                                                new_href = f'#page-{target_idx}-{anchor}'
                                            else:
                                                new_href = f'#page-{target_idx}'
                                            new_attrs.append((k, new_href))
                                        else:
                                            # Keep original if not found
                                            new_attrs.append((k, v))
                                    else:
                                        # External link or anchor, keep as-is
                                        new_attrs.append((k, v))
                                else:
                                    new_attrs.append((k, v))
                            attrs = new_attrs
                        else:
                            new_attrs = list(attrs)
                            attrs = new_attrs
                        
                        attr_str = ' '.join([f'{k}="{v}"' for k, v in attrs])
                        self.content.append(f'<{tag} {attr_str}>' if attr_str else f'<{tag}>')
                    else:
                        self.skip_depth += 1
                    
            def handle_endtag(self, tag):
                if tag == 'article' and self.in_article:
                    self.in_article = False
                    return
                
                if self.in_article:
                    if self.skip_depth > 0:
                        self.skip_depth -= 1
                        return
                    
                    self.content.append(f'</{tag}>')
                    
            def handle_data(self, data):
                if self.in_article and self.skip_depth == 0:
                    self.content.append(data)
        
        # Create a map of file paths to indices for link rewriting
        html_files_map = {}
        for idx, html_file in enumerate(html_files):
            rel_path = html_file.relative_to(site_dir)
            html_files_map[str(rel_path)] = idx
            # Also add without .html extension
            html_files_map[str(rel_path).replace('.html', '')] = idx
        
        for idx, html_file in enumerate(html_files):
            try:
                with open(html_file, 'r', encoding='utf-8') as f:
                    html_content = f.read()
                
                parser = ContentExtractor(idx, html_files_map)
                parser.feed(html_content)
                
                if parser.content:
                    rel_path = html_file.relative_to(site_dir)
                    
                    # Extract meaningful title (same logic as TOC)
                    page_title = None
                    import re
                    title_match = re.search(r'<title[^>]*>([^<]+)</title>', html_content)
                    if title_match:
                        page_title = title_match.group(1).strip()
                        if ' - ' in page_title:
                            page_title = page_title.split(' - ')[0].strip()
                    
                    if not page_title or page_title.lower() == 'index':
                        if rel_path.stem.lower() == 'index':
                            if rel_path.parent != Path('.'):
                                page_title = rel_path.parent.name.replace('-', ' ').replace('_', ' ').title()
                            else:
                                page_title = "Home"
                        else:
                            page_title = rel_path.stem.replace('-', ' ').replace('_', ' ').title()
                    
                    combined_html += f'\n    <div class="page-content" id="page-{idx}">\n'
                    combined_html += f'        <h1>{page_title}</h1>\n'
                    combined_html += ''.join(parser.content)
                    combined_html += '\n    </div>\n'
            except Exception as e:
                config.log(f"Warning: Could not process {html_file.name}: {e}", "‚ö†Ô∏è")
        
        combined_html += """
    <a href="#top" class="back-to-top">‚Üë Back to Top</a>
</body>
</html>
"""
        
        # Write combined HTML
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(combined_html)
        
        size_mb = html_path.stat().st_size / (1024 * 1024)
        config.log(f"Created {html_filename} ({size_mb:.1f}MB)", "‚úÖ")
        
    except Exception as e:
        print(f"‚ùå Combined HTML generation failed: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return False
    
    config.log(f"Combined HTML ready: {output_dir.relative_to(config.config_dir.parent)}/", "‚úÖ")
    return True


def build_pdf_target(config: UnifiedConfig, target_config: PdfTargetConfig) -> bool:
    """Build PDF documentation target using Playwright."""
    config.log(f"\n=== Building PDF Documentation ===", "üìù")
    
    # First ensure the site is built
    site_dir = config.config_dir / "../site"
    if not site_dir.exists():
        config.log("Site directory not found, building site first...", "")
        if 'site' in config.targets:
            site_config = config.targets['site']
            if isinstance(site_config, SiteTargetConfig):
                if not build_site_target(config, site_config):
                    return False
        else:
            print(f"‚ùå Site target not configured", file=sys.stderr)
            return False
    
    # Resolve output directory
    output_dir = config.config_dir / target_config.output_dir
    output_dir.mkdir(parents=True, exist_ok=True)
    
    pdf_filename = f"{config.project.name.replace(' ', '_')}-{config.version.current}.pdf"
    pdf_path = output_dir / pdf_filename
    
    config.log("Generating PDF with Playwright...", "")
    
    try:
        # Use Playwright to generate PDF
        from playwright.sync_api import sync_playwright
        
        config.log("Checking Playwright browsers...", "")
        
        # Try to launch browser, install if needed
        with sync_playwright() as p:
            try:
                browser = p.chromium.launch()
                browser.close()
                config.log("Playwright browsers ready", "‚úÖ")
            except Exception as browser_error:
                if "Executable doesn't exist" in str(browser_error):
                    config.log("Installing Playwright browsers (one-time setup, ~170MB)...", "‚è≥")
                    try:
                        # Install Chromium browser
                        install_result = subprocess.run(
                            [sys.executable, "-m", "playwright", "install", "chromium"],
                            capture_output=True,
                            text=True,
                            timeout=300  # 5 minute timeout
                        )
                        if install_result.returncode != 0:
                            print(f"‚ùå Failed to install Playwright browsers", file=sys.stderr)
                            print(install_result.stderr, file=sys.stderr)
                            return False
                        config.log("Playwright browsers installed", "‚úÖ")
                    except subprocess.TimeoutExpired:
                        print(f"‚ùå Browser installation timed out", file=sys.stderr)
                        return False
                else:
                    raise
        
        config.log("Building combined HTML for PDF...", "")
        
        # Use the combined-html target to generate the HTML
        if 'combined-html' in config.targets:
            combined_html_config = config.targets['combined-html']
            if isinstance(combined_html_config, CombinedHtmlTargetConfig):
                # Temporarily set same settings as PDF
                original_toc = combined_html_config.toc_levels
                combined_html_config.toc_levels = target_config.toc_levels
                
                if not build_combined_html_target(config, combined_html_config):
                    return False
                
                # Restore original
                combined_html_config.toc_levels = original_toc
                
                # Use the generated combined HTML
                combined_html_dir = config.config_dir / combined_html_config.output_dir
                combined_html_path = combined_html_dir / f"{config.project.name.replace(' ', '_')}-{config.version.current}-combined.html"
            else:
                print(f"‚ùå Combined HTML target not properly configured", file=sys.stderr)
                return False
        else:
            print(f"‚ùå Combined HTML target not configured", file=sys.stderr)
            return False
        
        # Verify the combined HTML exists
        if not combined_html_path.exists():
            print(f"‚ùå Combined HTML file not found: {combined_html_path}", file=sys.stderr)
            return False
        
        config.log("Rendering PDF from combined HTML...", "")
        
        with sync_playwright() as p:
            browser = p.chromium.launch()
            page = browser.new_page()
            
            # Load the combined HTML
            page.goto(f'file://{combined_html_path.resolve()}')
            
            # Wait for content to load (especially Mermaid diagrams)
            page.wait_for_load_state('networkidle')
            page.wait_for_timeout(3000)  # Extra time for Mermaid rendering
            
            # Generate PDF with options
            page.pdf(
                path=str(pdf_path),
                format='A4',
                print_background=True,
                margin={
                    'top': '20mm',
                    'right': '15mm',
                    'bottom': '20mm',
                    'left': '15mm'
                },
                display_header_footer=True,
                header_template=f'''
                    <div style="font-size: 10px; width: 100%; text-align: center; color: #666;">
                        {config.project.name} v{config.version.current}
                    </div>
                ''',
                footer_template='''
                    <div style="font-size: 10px; width: 100%; text-align: center; color: #666;">
                        <span class="pageNumber"></span> / <span class="totalPages"></span>
                    </div>
                '''
            )
            
            browser.close()
        
        # Clean up combined HTML
        if combined_html_path.exists():
            combined_html_path.unlink()
        
        # Check if PDF was created
        pdf_path = output_dir / pdf_filename
        if pdf_path.exists():
            size_mb = pdf_path.stat().st_size / (1024 * 1024)
            config.log(f"Created {pdf_filename} ({size_mb:.1f}MB)", "‚úÖ")
        else:
            print(f"‚ùå PDF file not found: {pdf_path}", file=sys.stderr)
            return False
        
    except ImportError:
        print(f"‚ùå Playwright not available. Run: playwright install chromium", file=sys.stderr)
        return False
    except Exception as e:
        print(f"‚ùå PDF generation failed: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return False
    
    config.log(f"PDF documentation ready: {output_dir.relative_to(config.config_dir.parent)}/", "‚úÖ")
    return True


def parse_args() -> argparse.Namespace:
    """Parse command-line arguments."""
    parser = argparse.ArgumentParser(
        description=f"MkDocs Build v{VERSION} - Multi-Target Build System",
        epilog="Examples:\n"
               "  mkdocs-build-v2 --config docs/mkdocs-build.json\n"
               "  mkdocs-build-v2 --config docs/mkdocs-build.json --target site\n"
               "  mkdocs-build-v2 --config docs/mkdocs-build.json --target all\n",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--config',
        type=Path,
        required=True,
        help='Path to unified config file (e.g., docs/mkdocs-build.json)'
    )
    parser.add_argument(
        '--target',
        default='mkdocs',
        help='Target(s) to build: mkdocs, site, electron, all (comma-separated)'
    )
    parser.add_argument(
        '--electron-build',
        action='store_true',
        help='Build Electron apps (override config)'
    )
    parser.add_argument(
        '--electron-platforms',
        help='Platforms to build: mac, win, linux, all (comma-separated)'
    )
    parser.add_argument(
        '--go-platforms',
        help='Go platforms to build: darwin/amd64, linux/amd64, windows/amd64, etc. (comma-separated)'
    )
    parser.add_argument(
        '--list-targets',
        action='store_true',
        help='List available targets and exit'
    )
    parser.add_argument(
        '--version',
        action='version',
        version=f'mkdocs-build v{VERSION}'
    )
    
    return parser.parse_args()


def main() -> int:
    """Main entry point."""
    args = parse_args()
    
    # Load configuration
    if not args.config.exists():
        print(f"‚ùå Config file not found: {args.config}", file=sys.stderr)
        return 1
    
    config = load_unified_config(args.config)
    
    # List targets mode
    if args.list_targets:
        print("Available targets:")
        for name, target in config.targets.items():
            status = "‚úÖ enabled" if target.enabled else "‚ùå disabled"
            print(f"  - {name}: {status}")
        return 0
    
    # Determine targets to build
    requested_targets: Set[str] = set()
    if args.target == 'all':
        requested_targets = {name for name, t in config.targets.items() if t.enabled}
    else:
        requested_targets = set(args.target.split(','))
    
    # Validate targets
    for target in requested_targets:
        if target not in config.targets:
            print(f"‚ùå Unknown target: {target}", file=sys.stderr)
            print(f"   Available: {', '.join(config.targets.keys())}", file=sys.stderr)
            return 1
        if not config.targets[target].enabled:
            print(f"‚ö†Ô∏è  Warning: Target '{target}' is disabled in config", file=sys.stderr)
    
    # Increment version and build count
    config.version.current = config.version.increment()
    config.version.build_count += 1
    save_version(config)
    
    config.log(f"MkDocs Build v{VERSION}", "")
    config.log(f"Version: {config.version.current} (build #{config.version.build_count})", "")
    config.log(f"Targets: {', '.join(sorted(requested_targets))}", "")
    
    # Build targets
    success = True
    for target_name in sorted(requested_targets):
        target_config = config.targets[target_name]
        
        try:
            if target_name == 'mkdocs' and isinstance(target_config, MkDocsTargetConfig):
                if not build_mkdocs_target(config, target_config):
                    success = False
                    break
            
            elif target_name == 'site' and isinstance(target_config, SiteTargetConfig):
                if not build_site_target(config, target_config):
                    success = False
                    break
            
            elif target_name == 'electron' and isinstance(target_config, ElectronTargetConfig):
                # Default to auto-build for electron target (always build unless explicitly disabled)
                auto_build = True  # Always build electron apps by default
                platforms = args.electron_platforms.split(',') if args.electron_platforms else None
                
                if not build_electron_target(config, target_config, auto_build, platforms):
                    success = False
                    break
            
            elif target_name == 'go' and isinstance(target_config, GoTargetConfig):
                platforms = args.go_platforms.split(',') if args.go_platforms else None
                
                if not build_go_target(config, target_config, platforms):
                    success = False
                    break
            
            elif target_name == 'site-zip' and isinstance(target_config, SiteZipTargetConfig):
                if not build_site_zip_target(config, target_config):
                    success = False
                    break
            
            elif target_name == 'combined-html' and isinstance(target_config, CombinedHtmlTargetConfig):
                if not build_combined_html_target(config, target_config):
                    success = False
                    break
            
            elif target_name == 'pdf' and isinstance(target_config, PdfTargetConfig):
                if not build_pdf_target(config, target_config):
                    success = False
                    break
        
        except Exception as e:
            print(f"‚ùå Error building {target_name}: {e}", file=sys.stderr)
            import traceback
            traceback.print_exc()
            success = False
            break
    
    if success:
        config.log(f"\nBuild complete!", "üéâ")
        return 0
    else:
        print(f"\n‚ùå Build failed", file=sys.stderr)
        return 1


if __name__ == '__main__':
    raise SystemExit(main())
